{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WVex7I_A_t9E"
      },
      "source": [
        "# Ultrasound Breast Tumour Classification Project\n",
        "\n",
        "The following Jupyter Notebook uses the PyTorch machine learning framework to build, train, and test on a custom convolutional neural network (CNN).\n",
        "\n",
        "The dataset used consists of images from breast ultrasound scans that are categorized into three classes depending on the tumour (or lack thereof): normal, benign, and malignant.\n",
        "\n",
        "However, as you will notice during the data preparation segment, we will not be making use of the normal images. The model will be trained on benign and malignant classes only.\n",
        "\n",
        "The dataset also contains mask images that segment where the tumour is. Those are not made use of in here, but rather used in other models (Mask RCNN and U-NET).\n",
        "\n",
        "Instead, there will be two models created and trained. One on the ultrasound images, and one on the mask images.\n",
        "\n",
        "The Notebook is divided as follows:\n",
        "\n",
        "* Data preparation\n",
        "\n",
        "* Setting up transforms\n",
        "\n",
        "* Creating the Dataset and DataLoader\n",
        "\n",
        "* Defining our model\n",
        "\n",
        "* Creating a training and testing loop\n",
        "\n",
        "* Instantiate our model and perform training and testing\n",
        "\n",
        "* Evaluate and compare results\n",
        "\n",
        "**Note**: Some of the logic seen here follows Daniel Bourke's PyTorch course, seen here: https://www.learnpytorch.io"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1E8BBefDkfUh"
      },
      "source": [
        "## How to run\n",
        "\n",
        "1. Click on `Runtime` from the bar above.\n",
        "2. Click on `change runtime type`.\n",
        "3. Select `GPU` as your hardware accelerator and save.\n",
        "4. Connect to a runtime by clicking on `Connect` in the top right-hand side.\n",
        "5. Click on `Runtime` again and `Run all`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "25MmDeuMf_bp"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXQRGXLnd6Ft"
      },
      "source": [
        "Download data zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqjPn4Q1c8Kk",
        "outputId": "c1412a4a-7cf5-4b2e-b607-1ebc44c09064"
      },
      "outputs": [],
      "source": [
        "# gdown allows downloading large files from Google Drive by passing id\n",
        "!gdown 1LljpoDlVfLoowaG6qAq_rCzX7W6wVjql"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pFCJzdf8d_VR"
      },
      "source": [
        "Importing all necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPq4WhjjAFxg"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from typing import Dict, List\n",
        "from pathlib import Path\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from timeit import default_timer as timer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tQH8Nu2ffR-p"
      },
      "source": [
        "Create `data` directory and unzip contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHkUunH4YAZF"
      },
      "outputs": [],
      "source": [
        "data_path = 'data'\n",
        "\n",
        "if os.path.isdir(data_path):\n",
        "  print(\"The directory already exists.\")\n",
        "else:\n",
        "    with zipfile.ZipFile(\"data.zip\", \"r\") as zip_ref:\n",
        "      zip_ref.extractall(\"data\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mtqDU5v7QTfn"
      },
      "source": [
        "The following three cells perform a similar data preperation logic.\n",
        "\n",
        "The first is for normal scans and masks, the second for benign, and third for malignant.\n",
        "\n",
        "* Sets paths for training and testing folders.\n",
        "* Create ratio that will be used to split training and testing data.\n",
        "* Fetches all the images for the specified class and shuffles them.\n",
        "* Splits the images into train and test sets.\n",
        "* Create the directories where we will be storing them.\n",
        "* Move the train and test data to the train and test directories, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq9LAKLH4KOU",
        "outputId": "32f44e2d-b151-451e-a655-6a5e81687f13"
      },
      "outputs": [],
      "source": [
        "# set the path to the folder containing the images\n",
        "path_to_normal = 'data/ultrasound/normal'\n",
        "\n",
        "if os.path.exists(path_to_normal):\n",
        "  \n",
        "  # set the path to the output folders for the train and test data\n",
        "  train_normal = 'data/train/normal'\n",
        "  test_normal = 'data/test/normal'\n",
        "\n",
        "  # set the train/test split ratio\n",
        "  train_ratio = 0.75\n",
        "\n",
        "  # get a list of all image file names in the folder\n",
        "  normal_image_filenames = os.listdir(path_to_normal)\n",
        "\n",
        "  # shuffle the image filenames to ensure a random split\n",
        "  random.shuffle(normal_image_filenames)\n",
        "\n",
        "  # split the image filenames into train and test sets\n",
        "  split_index = int(train_ratio * len(normal_image_filenames))\n",
        "  train_image_filenames = normal_image_filenames[:split_index]\n",
        "  test_image_filenames = normal_image_filenames[split_index:]\n",
        "\n",
        "  # create the train and test output folders if they don't already exist\n",
        "  if not os.path.exists(train_normal):\n",
        "      os.makedirs(train_normal)\n",
        "  if not os.path.exists(test_normal):\n",
        "      os.makedirs(test_normal)\n",
        "\n",
        "  # copy the train images to the train output folder\n",
        "  for filename in train_image_filenames:\n",
        "      source_path = os.path.join(path_to_normal, filename)\n",
        "      destination_path = os.path.join(train_normal, filename)\n",
        "      shutil.copy(source_path, destination_path)\n",
        "\n",
        "  # copy the test images to the test output folder\n",
        "  for filename in test_image_filenames:\n",
        "      source_path = os.path.join(path_to_normal, filename)\n",
        "      destination_path = os.path.join(test_normal, filename)\n",
        "      shutil.copy(source_path, destination_path)\n",
        "\n",
        "  print(f\"Finished splitting {len(normal_image_filenames)} images into train and test sets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac72fVDSkC9c",
        "outputId": "9f819df3-21a7-403e-8d45-e3242ea69f93"
      },
      "outputs": [],
      "source": [
        "# set the path to the folders containing the images\n",
        "path_to_benign = 'data/ultrasound/benign'\n",
        "\n",
        "if os.path.exists(path_to_benign):\n",
        "\n",
        "  # set the path to the output folders for the train and test data\n",
        "  train_benign = 'data/train/benign'\n",
        "  test_benign = 'data/test/benign'\n",
        "\n",
        "  # set the train/test split ratio\n",
        "  train_ratio = 0.75\n",
        "\n",
        "  # get a list of all image file names in the folder\n",
        "  benign_image_filenames = os.listdir(path_to_benign)\n",
        "\n",
        "  # shuffle the image filenames to ensure a random split\n",
        "  random.shuffle(benign_image_filenames)\n",
        "\n",
        "  # split the image filenames into train and test sets\n",
        "  split_index = int(train_ratio * len(benign_image_filenames))\n",
        "  train_image_filenames = benign_image_filenames[:split_index]\n",
        "  test_image_filenames = benign_image_filenames[split_index:]\n",
        "\n",
        "  # create the train and test output folders if they don't already exist\n",
        "  if not os.path.exists(train_benign):\n",
        "      os.makedirs(train_benign)\n",
        "  if not os.path.exists(test_benign):\n",
        "      os.makedirs(test_benign)\n",
        "\n",
        "  # copy the train images to the train output folder\n",
        "  for filename in train_image_filenames:\n",
        "      source_path = os.path.join(path_to_benign, filename)\n",
        "      destination_path = os.path.join(train_benign, filename)\n",
        "      shutil.copy(source_path, destination_path)\n",
        "\n",
        "  # copy the test images to the test output folder\n",
        "  for filename in test_image_filenames:\n",
        "      source_path = os.path.join(path_to_benign, filename)\n",
        "      destination_path = os.path.join(test_benign, filename)\n",
        "      shutil.copy(source_path, destination_path)\n",
        "\n",
        "  print(f\"Finished splitting {len(benign_image_filenames)} images into train and test sets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oTMw7jTksUs",
        "outputId": "dd6ff5d2-61e7-4a42-e2a9-8fb0f479724f"
      },
      "outputs": [],
      "source": [
        "# set the path to the folders containing the images\n",
        "path_to_malignant = 'data/ultrasound/malignant'\n",
        "\n",
        "if os.path.exists(path_to_malignant):\n",
        "\n",
        "  # set the path to the output folders for the train and test data\n",
        "  train_malignant = 'data/train/malignant'\n",
        "  test_malignant = 'data/test/malignant'\n",
        "\n",
        "  # set the train/test split ratio\n",
        "  train_ratio = 0.75\n",
        "\n",
        "  # get a list of all image file names in the folder\n",
        "  malignant_image_filenames = os.listdir(path_to_malignant)\n",
        "\n",
        "  # shuffle the image filenames to ensure a random split\n",
        "  random.shuffle(malignant_image_filenames)\n",
        "\n",
        "  # split the image filenames into train and test sets\n",
        "  split_index = int(train_ratio * len(malignant_image_filenames))\n",
        "  train_image_filenames = malignant_image_filenames[:split_index]\n",
        "  test_image_filenames = malignant_image_filenames[split_index:]\n",
        "\n",
        "  # create the train and test output folders if they don't already exist\n",
        "  if not os.path.exists(train_malignant):\n",
        "      os.makedirs(train_malignant)\n",
        "  if not os.path.exists(test_malignant):\n",
        "      os.makedirs(test_malignant)\n",
        "\n",
        "  # copy the train images to the train output folder\n",
        "  for filename in train_image_filenames:\n",
        "      source_path = os.path.join(path_to_malignant, filename)\n",
        "      destination_path = os.path.join(train_malignant, filename)\n",
        "      shutil.copy(source_path, destination_path)\n",
        "\n",
        "  # copy the test images to the test output folder\n",
        "  for filename in test_image_filenames:\n",
        "      source_path = os.path.join(path_to_malignant, filename)\n",
        "      destination_path = os.path.join(test_malignant, filename)\n",
        "      shutil.copy(source_path, destination_path)\n",
        "\n",
        "  print(f\"Finished splitting {len(malignant_image_filenames)} images into train and test sets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ced7ssmfAAAr"
      },
      "outputs": [],
      "source": [
        "# moving ultrasound dir out of 'data/' path\n",
        "check_dir = 'ultrasound'\n",
        "\n",
        "if os.path.isdir(check_dir):\n",
        "  print('Dataset already moved.')\n",
        "else:\n",
        "  root = '/content'\n",
        "  dataset = 'data/ultrasound'\n",
        "  shutil.move(dataset, root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKKhve5elM0N"
      },
      "outputs": [],
      "source": [
        "os.rename('ultrasound', 'original_data')\n",
        "os.rename('data', 'mask_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uraZZXioATn-",
        "outputId": "12a81300-d26b-4be8-b108-6c9278547faa"
      },
      "outputs": [],
      "source": [
        "# creating a new directory to store the ultrasound images separately from the mask images\n",
        "src = 'mask_images'\n",
        "dst = 'ultrasound_images'\n",
        "\n",
        "shutil.copytree(src, dst)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H8wBpC8omYg8"
      },
      "source": [
        "Loop through both directories we created above, and remove either the ultrasound image or mask image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ngpo08N_jN1M"
      },
      "outputs": [],
      "source": [
        "path_to_data_mask = 'mask_images/'\n",
        "path_to_data_ultrasound = 'ultrasound_images/'\n",
        "\n",
        "for directory_path, directory_names, file_names in os.walk(path_to_data_mask):\n",
        "    # loop through all image files in the current directory\n",
        "    for file_name in file_names:\n",
        "        if \"mask\" not in file_name and \"normal\" not in file_name:\n",
        "            # remove the file if it does not contains \"mask\" in its filename\n",
        "            os.remove(os.path.join(directory_path, file_name))\n",
        "\n",
        "for directory_path, directory_names, file_names in os.walk(path_to_data_ultrasound):\n",
        "    # loop through all image files in the current directory\n",
        "    for file_name in file_names:\n",
        "        if \"mask\" in file_name and \"normal\" not in file_name:\n",
        "            # remove the file if it contains \"mask\" in its filename\n",
        "            os.remove(os.path.join(directory_path, file_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25-_VgKtuPQA"
      },
      "outputs": [],
      "source": [
        "# removing the directories containing the normal scans\n",
        "shutil.rmtree(path_to_data_mask + '/train/normal')\n",
        "shutil.rmtree(path_to_data_mask + '/test/normal')\n",
        "\n",
        "shutil.rmtree(path_to_data_ultrasound + '/train/normal')\n",
        "shutil.rmtree(path_to_data_ultrasound + '/test/normal')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5E0QXiqbnC2-"
      },
      "source": [
        "## Set up our data agumentation/transforms and create the Dataset's and DataLoader's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGWVRzPHqaqW"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([\n",
        "    \n",
        "    transforms.Resize(size=(600, 700)),\n",
        "    transforms.ToTensor()\n",
        "\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zhI_xHNApqF2"
      },
      "source": [
        "Using PyTorch's generic built-in ImageFolder Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmg8rqpgqhwa"
      },
      "outputs": [],
      "source": [
        "# mask images\n",
        "\n",
        "train_dir_mask = 'mask_images/train'\n",
        "test_dir_mask = 'mask_images/test'\n",
        "\n",
        "train_data_mask = datasets.ImageFolder(root=train_dir_mask,\n",
        "                                  transform=data_transform) # transform for the data\n",
        "\n",
        "test_data_mask = datasets.ImageFolder(root=test_dir_mask,\n",
        "                                transform=data_transform) # transform for the data\n",
        "\n",
        "# ultrasound images\n",
        "\n",
        "train_dir_ultrasound = 'ultrasound_images/train'\n",
        "test_dir_ultrasound = 'ultrasound_images/test'\n",
        "\n",
        "train_data_ultrasound = datasets.ImageFolder(root=train_dir_ultrasound,\n",
        "                                  transform=data_transform) # transform for the data\n",
        "\n",
        "test_data_ultrasound = datasets.ImageFolder(root=test_dir_ultrasound,\n",
        "                                  transform=data_transform) # transform for the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzaJ1tdi-lrX"
      },
      "outputs": [],
      "source": [
        "# get class names and class names as dictionaries\n",
        "\n",
        "# mask images\n",
        "\n",
        "class_names_mask = train_data_mask.classes\n",
        "class_names_dict_mask = test_data_mask.class_to_idx\n",
        "\n",
        "# ultrasound images\n",
        "\n",
        "class_names_ultrasound = train_data_ultrasound.classes\n",
        "class_names_dict_ultrasound = test_data_ultrasound.class_to_idx\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "61UsVXFrp30K"
      },
      "source": [
        "Create train and test DataLoader's from Dataset's.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyVGopqH-umE"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# mask images\n",
        "\n",
        "train_dataloader_mask = DataLoader(dataset=train_data_mask,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              num_workers=NUM_WORKERS # how many cpu cores (use os.cpu_count() to use all)\n",
        ")\n",
        "\n",
        "test_dataloader_mask = DataLoader(dataset=test_data_mask,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=False,\n",
        "                              num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "# ultrasound images\n",
        "\n",
        "train_dataloader_ultrasound = DataLoader(dataset=train_data_ultrasound,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "test_dataloader_ultrasound = DataLoader(dataset=test_data_ultrasound,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=False,\n",
        "                              num_workers=NUM_WORKERS \n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rk4ewt7Vq1wl"
      },
      "source": [
        "Setting up device-agnostic code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R8aQ4jlzA6hu",
        "outputId": "ad8fe486-37a2-4316-e346-350c041f2e0f"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQ0_XrcAJmM"
      },
      "source": [
        "## Creating our model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6eqlK1G7raPF"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-d-PLRESQUg"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "  \"\"\"\n",
        "  Basic CNN model architecture\n",
        "  \"\"\"\n",
        "  def __init__(self, \n",
        "               input_shape,\n",
        "               hidden_units,\n",
        "               output_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=16, # 16 feature maps\n",
        "                  kernel_size=3,\n",
        "                  stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=16,\n",
        "                  out_channels=16,\n",
        "                  kernel_size=3,\n",
        "                  stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2) # default stride value is same as kernel size\n",
        "    )\n",
        "    self.conv_block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=16,\n",
        "                  out_channels=64,\n",
        "                  kernel_size=5,\n",
        "                  stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=64,\n",
        "                  out_channels=64,\n",
        "                  kernel_size=5,\n",
        "                  stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=64*145*170, # previous output * width * height (the values here can obviously be calculated by hand by mathematically seeing what the previous layers are doing to the image, however set a random number here and do a forward pass and print the shape of the image before getting here and then update the value accordingly)\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv_block1(x)\n",
        "    # print(x.shape)\n",
        "    x = self.conv_block2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    # print(x.shape)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-I8KtUkBfI4Q"
      },
      "source": [
        "## Create train and test loops functions\n",
        "\n",
        "* `train_step()` - takes a model and dataloader and trains the model on the dataloader.\n",
        "\n",
        "* `test_step()` - take a model and a dataloader and evaluates the model on the dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3EfQPBaq-y2"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device=device):\n",
        "  \n",
        "  # train mode\n",
        "  model.train()\n",
        "\n",
        "  # set up loss and accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # loop through dataloader batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "    # send to device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # calculate accuracy metric\n",
        "    y_pred_probs = torch.softmax(y_pred, dim=1)\n",
        "    y_pred_class = torch.argmax(y_pred_probs, dim=1)\n",
        "    \n",
        "    train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
        "\n",
        "  # adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "\n",
        "  return train_loss, train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7w-laFbtA2p"
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               device=device):\n",
        "  \n",
        "  # eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # set up loss and accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # turn on inference mode\n",
        "  with torch.inference_mode():\n",
        "    \n",
        "  # loop through dataloader batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "      # send to device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      test_pred = model(X)\n",
        "\n",
        "      # calculate loss\n",
        "      loss = loss_fn(test_pred, y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      # calculate accuracy metric\n",
        "      test_pred_labels = torch.argmax(torch.softmax(test_pred, dim=1), dim=1)\n",
        "      test_acc += (test_pred_labels == y).sum().item() / len(test_pred)\n",
        "\n",
        "  # adjust metrics to get average loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "\n",
        "  return test_loss, test_acc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "okwN4IVBuVmR"
      },
      "source": [
        "Creating a `train()` function to combine train and test loops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHJl0_fykVWz"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# create a train function \n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs,\n",
        "          device = device):\n",
        "  \n",
        "   # create results dictionary\n",
        "   results = {\"train_loss\": [],\n",
        "              \"train_acc\": [],\n",
        "              \"test_loss\": [],\n",
        "              \"test_acc\": []}\n",
        "    \n",
        "\n",
        "    # loop through training and testing steps \n",
        "   for epoch in tqdm(range(epochs)):\n",
        "\n",
        "     train_loss, train_acc = train_step(model,\n",
        "                                        train_dataloader,\n",
        "                                        loss_fn,\n",
        "                                        optimizer,\n",
        "                                        device)\n",
        "     \n",
        "     test_loss, test_acc = test_step(model,\n",
        "                                    test_dataloader,\n",
        "                                    loss_fn,\n",
        "                                    device)\n",
        "     \n",
        "     print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
        "\n",
        "     # update results dictionary\n",
        "     results[\"train_loss\"].append(train_loss)\n",
        "     results[\"train_acc\"].append(train_acc)\n",
        "     results[\"test_loss\"].append(test_loss)\n",
        "     results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "   return results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x_oF5MDoAQ9g"
      },
      "source": [
        "## Train and test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZEPlZ3Qc0am"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "input_shape = 3\n",
        "hidden_units = 10\n",
        "NUM_EPOCHS = 20"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kIP7Ojl_tFIc"
      },
      "source": [
        "Mask images training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "d0bae2249edf4cfc8b853633d6b69151",
            "c34ff0b175784002964dbe9f56058e27",
            "3c2cce650afb4c4ea283a758e7f16dcf",
            "23c47eedb174412fa144bc5a802e2f59",
            "de2c0e5afcf24f32bae8c5e2b7677f93",
            "6b66073e8c844e4c82ccf7889d746cd7",
            "04087b21bb944f1fb0a3c6412f226992",
            "2adb6b23f2cb4b12a3edb591efbfffdf",
            "a6c82ce94cb64a4f81f75c8d41f45c9e",
            "16d39a9526ae425a921861831ddae461",
            "9fcbf80a14d94e0eb2d7ac3beccadae2"
          ]
        },
        "id": "GL-_FTUVgxfn",
        "outputId": "58d63bce-7a39-4bd7-d8e4-025775f1744c"
      },
      "outputs": [],
      "source": [
        "mymodel_mask = MyModel(input_shape=input_shape,\n",
        "                      hidden_units=hidden_units,\n",
        "                      output_shape=len(train_data_mask.classes)).to(device)\n",
        "\n",
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "mask_optimizer = torch.optim.Adam(params=mymodel_mask.parameters(),\n",
        "                             lr=0.001,\n",
        "                             weight_decay=0.01)\n",
        "\n",
        "# timer\n",
        "start_time = timer()\n",
        "\n",
        "# train\n",
        "model_1_results_mask = train(model=mymodel_mask,\n",
        "                            train_dataloader=train_dataloader_mask,\n",
        "                            test_dataloader=test_dataloader_mask,\n",
        "                            optimizer=mask_optimizer,\n",
        "                            loss_fn=loss_fn,\n",
        "                            epochs=NUM_EPOCHS,\n",
        "                            device=device)\n",
        "\n",
        "end_time = timer()\n",
        "total_time = time.strftime(\"%M:%S\", time.gmtime(end_time - start_time))\n",
        "print(f\"Total training time for mask model: {total_time} minutes.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LyQ3hNM2Adjs"
      },
      "source": [
        "Ultrasound images training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "cc3970d139064b8cb7ef810357270597",
            "6512f812aa844b96b213c357a3e803c4",
            "0948821f153f43c6b29de26010b4661c",
            "f36f517e5be847f795e4e5c4b13c6dec",
            "9ecea533e1e249f884102772fdf10f06",
            "26d7902db32d4a80803f58adde991cbd",
            "439e8a5a9b994dd9b48933f5313943b5",
            "0b0ae67aff5e4e03bd58c7cae0737908",
            "2fcf0d97cdb7400fa2b19b01906b8225",
            "6c5e63af429a40df920411b4cf8ac79f",
            "6afc645a51174d988363cfb659f6cb89"
          ]
        },
        "id": "YGBC9UxWroj5",
        "outputId": "65c322aa-7a45-4297-bccf-cc99dd28f92f"
      },
      "outputs": [],
      "source": [
        "mymodel_ultrasound = MyModel(input_shape=input_shape,\n",
        "                            hidden_units=hidden_units,\n",
        "                            output_shape=len(train_data_ultrasound.classes)).to(device)\n",
        "\n",
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "ultrasound_optimizer = torch.optim.Adam(params=mymodel_ultrasound.parameters(),\n",
        "                             lr=0.001,\n",
        "                             weight_decay=0.01)\n",
        "                  \n",
        "# timer\n",
        "start_time = timer()\n",
        "\n",
        "# train\n",
        "model_1_results_ultrasound = train(model=mymodel_ultrasound,\n",
        "                                  train_dataloader=train_dataloader_ultrasound,\n",
        "                                  test_dataloader=test_dataloader_ultrasound,\n",
        "                                  optimizer=ultrasound_optimizer,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  epochs=NUM_EPOCHS,\n",
        "                                  device=device)\n",
        "\n",
        "end_time = timer()\n",
        "total_time = time.strftime(\"%M:%S\", time.gmtime(end_time - start_time))\n",
        "print(f\"Total training time for ultrasound model: {total_time} minutes.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "voS_h7OVxMS4"
      },
      "source": [
        "## Saving our model for later use if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oyEIOU3ctJh"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, filename):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJTXpauWc7Lf"
      },
      "outputs": [],
      "source": [
        "mask_state = {\n",
        "    \"state_dict\": mymodel_mask.state_dict(),\n",
        "    \"optimizer\": mask_optimizer.state_dict()\n",
        "}\n",
        "\n",
        "ultrasound_state = {\n",
        "    \"state_dict\": mymodel_ultrasound.state_dict(),\n",
        "    \"optimizer\": ultrasound_optimizer.state_dict()\n",
        "}\n",
        "\n",
        "save_checkpoint(mask_state, \"MyModel_Mask.pth\")\n",
        "save_checkpoint(ultrasound_state, \"MyModel_Ultrasound.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3Z2Amo8c_9w"
      },
      "outputs": [],
      "source": [
        "model = MyModel(input_shape=3,\n",
        "                hidden_units=10,\n",
        "                output_shape=2).to(device)\n",
        "filename = \"MyModel_Ultrasound.pth\"\n",
        "load_checkpoint(torch.load(filename), model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2IVTv66_m00f"
      },
      "source": [
        "## Evaluation and compare model results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4FhTcgwNiHW"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(results: Dict[str, List[float]], title):\n",
        "  \"\"\"\n",
        "  Plots a training curve of a results dictionary\n",
        "  \"\"\"\n",
        "\n",
        "  # get loss values of dictionary\n",
        "  loss = results[\"train_loss\"]\n",
        "  test_loss = results[\"test_loss\"]\n",
        "\n",
        "  # get accuracy values of dictionary\n",
        "  accuracy = results[\"train_acc\"]\n",
        "  test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "  # how many epochs\n",
        "  epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "  # set up plot and title\n",
        "  plt.figure(figsize=(15, 7))\n",
        "  plt.suptitle(title)\n",
        "\n",
        "  # plot loss\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, loss, label=\"train_loss\")\n",
        "  plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # plot accuracy\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
        "  plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "mGZ5p7x2jVDB",
        "outputId": "6903c1d1-beab-4f44-cdd4-cb3e63886d0b"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(model_1_results_mask, \"Mask Images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "nVVxFywIsBuw",
        "outputId": "b5e86b82-bd34-4d96-e71a-91c54d863b96"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(model_1_results_ultrasound, \"Ultrasound Images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aohf-0lpQbz"
      },
      "outputs": [],
      "source": [
        "mask_df = pd.DataFrame(model_1_results_mask)\n",
        "ultrasound_df = pd.DataFrame(model_1_results_ultrasound)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "rsdXaZ8rp6iL",
        "outputId": "e14bf049-e64e-43b5-bb58-cc6cf42e07a3"
      },
      "outputs": [],
      "source": [
        "# set up plot\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "# get number of epochs\n",
        "epochs = range(len(mask_df))\n",
        "\n",
        "# plot train loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, mask_df[\"train_loss\"], label=\"Mask Model\")\n",
        "plt.plot(epochs, ultrasound_df[\"train_loss\"], label=\"Ultrasound Model\", color='grey')\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# plot test loss\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, mask_df[\"test_loss\"], label=\"Mask Model\")\n",
        "plt.plot(epochs, ultrasound_df[\"test_loss\"], label=\"Ultrasound Model\", color='grey')\n",
        "plt.title(\"Test Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# plot train acc\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(epochs, mask_df[\"train_acc\"], label=\"Mask Model\")\n",
        "plt.plot(epochs, ultrasound_df[\"train_acc\"], label=\"Ultrasound Model\", color='grey')\n",
        "plt.title(\"Train Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0.0, 1.0)\n",
        "plt.legend()\n",
        "\n",
        "# plot test acc\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(epochs, mask_df[\"test_acc\"], label=\"Mask Model\")\n",
        "plt.plot(epochs, ultrasound_df[\"test_acc\"], label=\"Ultrasound Model\", color='grey')\n",
        "plt.title(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0.0, 1.0)\n",
        "plt.legend()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QiKhj-4G0UGN"
      },
      "source": [
        "## Using our model to predict on a custom image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9CNzkJ72EYd"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "import torchvision\n",
        "\n",
        "# fetch custom image (malignant)\n",
        "response = requests.get('https://prod-images-static.radiopaedia.org/images/2367196/28cf3593e1270d0c73c02c27db7b4f_big_gallery.JPG')\n",
        "img = Image.open(BytesIO(response.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDBf5UYbg2v3"
      },
      "outputs": [],
      "source": [
        "# converting the PIL image to a tensor\n",
        "tensor_uint8 = torchvision.transforms.functional.pil_to_tensor(img)\n",
        "\n",
        "# converting our image to torch.float32 AND dividing by 255 to make all our values range from 0 to 1\n",
        "custom_image = tensor_uint8.type(torch.float32) / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhdk_fPu7jpV",
        "outputId": "ce6526d8-754f-4285-d3a9-860c3db67f6f"
      },
      "outputs": [],
      "source": [
        "# resize image using transform\n",
        "custom_image_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(600, 700))\n",
        "])\n",
        "\n",
        "custom_image_transformed = custom_image_transform(custom_image)\n",
        "\n",
        "print(f\"Original shape: {custom_image.shape}\")\n",
        "print(f\"Transformed shape: {custom_image_transformed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbOP3Mm78qhF"
      },
      "outputs": [],
      "source": [
        "# add a batch size\n",
        "custom_image_transformed = custom_image_transformed.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8JpfS5v83Z4"
      },
      "outputs": [],
      "source": [
        "# forward pass on model\n",
        "\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  custom_image_pred = model(custom_image_transformed.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE6MJLmVBMDK",
        "outputId": "c68bfd63-071b-431b-aaf6-eab0b02e5a5f"
      },
      "outputs": [],
      "source": [
        "custom_image_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsP_2aLdBSdw",
        "outputId": "37c3d78d-8e61-4766-9325-80fd60ddc118"
      },
      "outputs": [],
      "source": [
        "# logits to prediction probabilities\n",
        "\n",
        "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
        "custom_image_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "742slEbeBfy9",
        "outputId": "b048368d-74cf-4186-d793-d634d1801e66"
      },
      "outputs": [],
      "source": [
        "# prediction probabilities to prediction labels\n",
        "\n",
        "custom_image_pred_labels = torch.argmax(custom_image_pred_probs, dim=1)\n",
        "custom_image_pred_labels"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t2TtMfq7BzmU"
      },
      "source": [
        "Now we can finally index our class names dictionary and output the predicted class. In this case, it is benign."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "StjT0lAwBrUr",
        "outputId": "a34be18d-7f6c-43a8-e42e-f0d10453eec4"
      },
      "outputs": [],
      "source": [
        "class_names_ultrasound[custom_image_pred_labels]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ANNsD_rGKtfF"
      },
      "source": [
        "## Using a pre-trained model\n",
        "\n",
        "If you would like to use a pre-trained model instead of training one, then please follow the steps:\n",
        "\n",
        "* Copy the model's `.pth` file to Google Colab's root files directory.\n",
        "\n",
        "* After it has finished uploading, run the [Data preparation](#scrollTo=25MmDeuMf_bp) code cells to import all required libraries and set up the data properly.\n",
        "\n",
        "* Then, go to the [model definition here](#scrollTo=M-d-PLRESQUg&line=4&uniqifier=1) and run to set up the model.\n",
        "\n",
        "* Afterwards, set the `LOAD_MODEL` bool below to true and run the code cell to load the model.\n",
        "\n",
        "* When the model has finished loading, run the cells within the following code blocks:\n",
        "\n",
        "  * [Set up our data agumentation/transforms and create the Dataset's and DataLoader's](#scrollTo=5E0QXiqbnC2-)\n",
        "  * [Using our model to predict on a custom image](#scrollTo=QiKhj-4G0UGN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXoTJuZz7wKK"
      },
      "outputs": [],
      "source": [
        "LOAD_MODEL = False\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "if LOAD_MODEL:\n",
        "  model = MyModel(input_shape=3,\n",
        "                  hidden_units=20,\n",
        "                  output_shape=3).to(device)\n",
        "  filename = \"MyModel_Ultrasound.pth\"\n",
        "  load_checkpoint(torch.load(filename), model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04087b21bb944f1fb0a3c6412f226992": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0948821f153f43c6b29de26010b4661c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0ae67aff5e4e03bd58c7cae0737908",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fcf0d97cdb7400fa2b19b01906b8225",
            "value": 20
          }
        },
        "0b0ae67aff5e4e03bd58c7cae0737908": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d39a9526ae425a921861831ddae461": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c47eedb174412fa144bc5a802e2f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d39a9526ae425a921861831ddae461",
            "placeholder": "​",
            "style": "IPY_MODEL_9fcbf80a14d94e0eb2d7ac3beccadae2",
            "value": " 20/20 [05:36&lt;00:00, 16.68s/it]"
          }
        },
        "26d7902db32d4a80803f58adde991cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2adb6b23f2cb4b12a3edb591efbfffdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fcf0d97cdb7400fa2b19b01906b8225": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c2cce650afb4c4ea283a758e7f16dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2adb6b23f2cb4b12a3edb591efbfffdf",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6c82ce94cb64a4f81f75c8d41f45c9e",
            "value": 20
          }
        },
        "439e8a5a9b994dd9b48933f5313943b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6512f812aa844b96b213c357a3e803c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26d7902db32d4a80803f58adde991cbd",
            "placeholder": "​",
            "style": "IPY_MODEL_439e8a5a9b994dd9b48933f5313943b5",
            "value": "100%"
          }
        },
        "6afc645a51174d988363cfb659f6cb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b66073e8c844e4c82ccf7889d746cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5e63af429a40df920411b4cf8ac79f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ecea533e1e249f884102772fdf10f06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fcbf80a14d94e0eb2d7ac3beccadae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6c82ce94cb64a4f81f75c8d41f45c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c34ff0b175784002964dbe9f56058e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b66073e8c844e4c82ccf7889d746cd7",
            "placeholder": "​",
            "style": "IPY_MODEL_04087b21bb944f1fb0a3c6412f226992",
            "value": "100%"
          }
        },
        "cc3970d139064b8cb7ef810357270597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6512f812aa844b96b213c357a3e803c4",
              "IPY_MODEL_0948821f153f43c6b29de26010b4661c",
              "IPY_MODEL_f36f517e5be847f795e4e5c4b13c6dec"
            ],
            "layout": "IPY_MODEL_9ecea533e1e249f884102772fdf10f06"
          }
        },
        "d0bae2249edf4cfc8b853633d6b69151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c34ff0b175784002964dbe9f56058e27",
              "IPY_MODEL_3c2cce650afb4c4ea283a758e7f16dcf",
              "IPY_MODEL_23c47eedb174412fa144bc5a802e2f59"
            ],
            "layout": "IPY_MODEL_de2c0e5afcf24f32bae8c5e2b7677f93"
          }
        },
        "de2c0e5afcf24f32bae8c5e2b7677f93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f36f517e5be847f795e4e5c4b13c6dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5e63af429a40df920411b4cf8ac79f",
            "placeholder": "​",
            "style": "IPY_MODEL_6afc645a51174d988363cfb659f6cb89",
            "value": " 20/20 [05:47&lt;00:00, 17.32s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
